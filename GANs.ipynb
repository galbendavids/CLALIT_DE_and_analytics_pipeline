{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/galbendavids/CLALIT_DE_and_analytics_pipeline/blob/main/GANs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QvqHYA3gPbsz"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "import os\n",
        "import pathlib\n",
        "from scipy.io import arff\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import glob\n",
        "import imageio\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import os\n",
        "import PIL\n",
        "from tensorflow.keras import layers\n",
        "import time\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "from IPython import display"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eGN16ddKPk1p",
        "outputId": "a295f97c-c528-4cac-dd0f-790434dcba0e"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive/\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wtqVTLm9hiVV"
      },
      "source": [
        "\"\"\"\n",
        "def df_with_one_hot_endcoding(df):\n",
        "  one_hot_encoded_df = pd.get_dummies(df)\n",
        "  return one_hot_encoded_df\n",
        "\"\"\"  \n",
        "\n",
        "def udummy_german_credit(german_credit_df_new):\n",
        "    german_credit_df_new_copy = german_credit_df_new.copy()\n",
        "    for col_number in [1, 3, 4, 6, 7, 9, 10, 12, 14, 15, 17, 19, 20, 21]:\n",
        "        start = None\n",
        "        end = None\n",
        "        col_to_remove = []\n",
        "        for counter, col in enumerate(german_credit_df_new.columns):\n",
        "            if f\"{col_number}_b\" in col:\n",
        "                col_to_remove.append(col)\n",
        "                if start is None:\n",
        "                    start = counter\n",
        "            elif start is not None:\n",
        "                end = counter\n",
        "                german_credit_df_new_copy[f'{col_number}'] = (german_credit_df_new.iloc[:, start:end]).idxmax(1)\n",
        "                german_credit_df_new_copy.drop(col_to_remove, axis=1, inplace=True)\n",
        "                break\n",
        "            if f\"{col_number}_b\" in col and (counter + 1) == len(german_credit_df_new.columns):\n",
        "                end = counter\n",
        "                german_credit_df_new_copy[f'{col_number}'] = (german_credit_df_new.iloc[:, start:end]).idxmax(1)\n",
        "                german_credit_df_new_copy.drop(col_to_remove, axis=1, inplace=True)\n",
        "                break\n",
        "    return german_credit_df_new_copy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TkTVgupmh-51"
      },
      "source": [
        "def read_and_normlize_dataset(name):\n",
        "    if name == \"diabetes\":\n",
        "        dataset = arff.loadarff('/content/drive/MyDrive/deep4/diabetes.arff')\n",
        "        datasets_df = pd.DataFrame(dataset[0])\n",
        "        dataset_without_label = datasets_df.iloc[:, :-1]\n",
        "        scaler = StandardScaler()\n",
        "        dataset_without_label[['preg', 'plas', 'pres', 'skin', \"insu\", \"mass\", \"pedi\", \"age\"]] = scaler.fit_transform(dataset_without_label[['preg', 'plas', 'pres', 'skin', \"insu\", \"mass\", \"pedi\", \"age\"]])\n",
        "        return dataset_without_label.to_numpy(), scaler, dataset_without_label.columns\n",
        "    else:\n",
        "        dataset = arff.loadarff('/content/drive/MyDrive/deep4/german_credit.arff')\n",
        "        datasets_df = pd.DataFrame(dataset[0])\n",
        "        dataset_without_label = datasets_df.iloc[:, :-1]\n",
        "        dataset_one_hot_encodeing = pd.get_dummies(dataset_without_label)\n",
        "        scaler = StandardScaler()\n",
        "        dataset_one_hot_encodeing[[\"2\",\"5\",\"8\",\"11\",\"13\",\"16\",\"18\"]] = scaler.fit_transform(dataset_one_hot_encodeing[[\"2\",\"5\",\"8\",\"11\",\"13\",\"16\",\"18\"]])\n",
        "        return dataset_one_hot_encodeing.to_numpy(), scaler, dataset_one_hot_encodeing.columns\n",
        "        "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dFdvR9owRXKx"
      },
      "source": [
        "def create_generator_model(input_shape, layer_dim, output_dim):\n",
        "    # TODO change\n",
        "    input= tf.keras.layers.Input(shape=input_shape)\n",
        "    layer_output = tf.keras.layers.Dense(layer_dim, activation=\"relu\")(input)\n",
        "    layer_output = tf.keras.layers.Dense(layer_dim * 3, activation='relu')(layer_output)\n",
        "    layer_output = tf.keras.layers.Dense(layer_dim * 4, activation='relu')(layer_output)\n",
        "    layer_output = tf.keras.layers.Dense(layer_dim * 4, activation='relu')(layer_output)\n",
        "    layer_output = tf.keras.layers.Dense(output_dim)(layer_output)\n",
        "    return tf.keras.Model(inputs=input, outputs=layer_output)\n",
        "\n",
        "def create_discriminator_model(input_shape, layer_dim):\n",
        "    input = tf.keras.layers.Input(shape=input_shape)\n",
        "    layer_output = tf.keras.layers.Dense(layer_dim * 4, activation='relu')(input)\n",
        "    layer_output = tf.keras.layers.Dense(layer_dim * 4, activation='relu')(layer_output)\n",
        "    layer_output = tf.keras.layers.Dense(layer_dim * 3, activation='relu')(layer_output)\n",
        "    layer_output = tf.keras.layers.Dense(layer_dim * 3, activation='relu')(layer_output)\n",
        "    layer_output = tf.keras.layers.Dense(layer_dim, activation='relu')(layer_output)\n",
        "    layer_output = tf.keras.layers.Dense(1, activation='sigmoid')(layer_output)\n",
        "    return tf.keras.Model(inputs=input, outputs=layer_output)\n",
        "\n",
        "def create_generator_model_credit(input_shape, layer_dim, output_dim):\n",
        "    # TODO change\n",
        "    input= tf.keras.layers.Input(shape=input_shape)\n",
        "    layer_output = tf.keras.layers.Dense(layer_dim, activation=\"relu\")(input)\n",
        "    layer_output = tf.keras.layers.Dense(layer_dim * 3, activation='relu')(layer_output)\n",
        "    layer_output = tf.keras.layers.Dense(layer_dim * 3, activation='relu')(layer_output)\n",
        "    layer_output = tf.keras.layers.Dense(layer_dim * 4, activation='relu')(layer_output)\n",
        "    layer_output = tf.keras.layers.Dense(output_dim)(layer_output)\n",
        "    return tf.keras.Model(inputs=input, outputs=layer_output)\n",
        "\n",
        "def create_discriminator_model_credit(input_shape, layer_dim):\n",
        "    input = tf.keras.layers.Input(shape=input_shape)\n",
        "    layer_output = tf.keras.layers.Dense(layer_dim * 5, activation='relu')(input)\n",
        "    layer_output = tf.keras.layers.Dense(layer_dim * 5, activation='relu')(layer_output)\n",
        "    layer_output = tf.keras.layers.Dense(layer_dim * 3, activation='relu')(layer_output)\n",
        "    layer_output = tf.keras.layers.Dense(layer_dim * 3, activation='relu')(layer_output) # remove\n",
        "    layer_output = tf.keras.layers.Dense(layer_dim, activation='relu')(layer_output)\n",
        "    layer_output = tf.keras.layers.Dense(1, activation='sigmoid')(layer_output)\n",
        "    return tf.keras.Model(inputs=input, outputs=layer_output)\n",
        "\n",
        "def discriminator_loss(real_data_disc_output, fake_data_disc_output, bce):\n",
        "    real_data_loss = bce(tf.ones_like(real_data_disc_output), real_data_disc_output)\n",
        "    fake_data_loss = bce(tf.zeros_like(fake_data_disc_output), fake_data_disc_output)\n",
        "    loss = real_data_loss + fake_data_loss\n",
        "    return loss\n",
        "\n",
        "def generator_loss(fake_data_disc_output, bce):\n",
        "    return bce (tf.ones_like(fake_data_disc_output), fake_data_disc_output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pNsY6JvJRyeS"
      },
      "source": [
        "def train_step(samples, generator, discriminator, batch_size, input_shape, generator_optimizer, discriminator_optimizer, bce):\n",
        "    noise = tf.random.normal([batch_size, input_shape])\n",
        "\n",
        "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
        "      generated_samples = generator(noise, training=True)\n",
        "\n",
        "      real_data_disc_output = discriminator(samples, training=True)\n",
        "      fake_data_disc_output = discriminator(generated_samples, training=True)\n",
        "      gen_loss = generator_loss(fake_data_disc_output, bce)\n",
        "      disc_loss = discriminator_loss(real_data_disc_output, fake_data_disc_output, bce)\n",
        "\n",
        "    grad_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
        "    grad_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
        "\n",
        "    generator_optimizer.apply_gradients(zip(grad_of_generator, generator.trainable_variables))\n",
        "    discriminator_optimizer.apply_gradients(zip(grad_of_discriminator, discriminator.trainable_variables))\n",
        "    return gen_loss, disc_loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lc7Mp9AmjuEo"
      },
      "source": [
        "def train_model(name, epochs, input_shape):\n",
        "    dataset, scaler, columes = read_and_normlize_dataset(name)\n",
        "    output_dim = dataset.shape[1]\n",
        "    batch_size = 32\n",
        "\n",
        "    if name == \"german_credit\":\n",
        "        layer_size_gen = 1024\n",
        "        layer_size_disc = 256\n",
        "        disc_lr = 1e-4\n",
        "        gen_lr = 1e-4\n",
        "        generator = create_generator_model_credit((input_shape, ), layer_size_gen, output_dim)\n",
        "        discriminator = create_discriminator_model_credit((output_dim, ), layer_size_disc)\n",
        "    else: # diabetes\n",
        "        layer_size_gen = 128\n",
        "        layer_size_disc = 256\n",
        "        disc_lr = 1e-5\n",
        "        gen_lr = 1e-5\n",
        "        generator = create_generator_model((input_shape, ), layer_size_gen, output_dim)\n",
        "        discriminator = create_discriminator_model((output_dim, ), layer_size_disc)\n",
        "\n",
        "    train_dataset = tf.data.Dataset.from_tensor_slices(dataset).batch(batch_size)\n",
        "    \n",
        "    generator_optimizer = tf.keras.optimizers.Adam(gen_lr)\n",
        "    discriminator_optimizer = tf.keras.optimizers.Adam(disc_lr)\n",
        "    history = {}\n",
        "    history[\"gen\"] = []\n",
        "    history[\"disc\"] = [] \n",
        "    bce = tf.keras.losses.BinaryCrossentropy()\n",
        "    for epoch in range(epochs):\n",
        "        for samples_batch in train_dataset:\n",
        "            gen_loss, disc_loss = train_step(samples_batch, generator, discriminator, batch_size, input_shape, generator_optimizer, discriminator_optimizer, bce)\n",
        "      \n",
        "        history[\"gen\"].append(gen_loss.numpy())\n",
        "        history[\"disc\"].append(disc_loss.numpy())  \n",
        "        print(f\"reach epoch number {epoch + 1}\")\n",
        "    return history, generator, discriminator, scaler, columes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KtBFzXDK4f0f"
      },
      "source": [
        "def plot(history):\n",
        "    \"\"\" \n",
        "    this method plot the accuracy and the loss of the network\n",
        "    \"\"\"\n",
        "    plt.plot(history['gen'])\n",
        "    plt.plot(history['disc'])\n",
        "    plt.title('loss')\n",
        "    plt.ylabel('loss')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend(['gen', 'disc'])\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UTpbp9XIiHct"
      },
      "source": [
        "def label_samples(generator, discriminator, generator_output):\n",
        "    samples_label_as_real_index = []\n",
        "    samples_label_as_fake_index = []\n",
        "    \n",
        "    for index, sample in enumerate(generator_output):\n",
        "        if discriminator(np.array([sample])) > 0.5:\n",
        "            samples_label_as_real_index.append(index)\n",
        "        else:\n",
        "            samples_label_as_fake_index.append(index)\n",
        "    return samples_label_as_real_index, samples_label_as_fake_index\n",
        "\n",
        "def print_results(history, name, num_examples_to_generate, dataset_columns, generator, discriminator, input_shape, scaler):\n",
        "    plot(history)\n",
        "    seed = tf.random.normal([num_examples_to_generate, input_shape])\n",
        "    generator_output = generator(seed).numpy()\n",
        "    df = pd.DataFrame(data= generator_output.copy(), columns=dataset_columns)\n",
        "    if name == \"german_credit\":\n",
        "        df[[\"2\",\"5\",\"8\",\"11\",\"13\",\"16\",\"18\"]] = scaler.inverse_transform(df[[\"2\",\"5\",\"8\",\"11\",\"13\",\"16\",\"18\"]])\n",
        "        samples_label_as_real, samples_label_as_fake = label_samples(generator, discriminator, generator_output)\n",
        "        print(\"number of output the bit the discriminator\")\n",
        "        print(len(samples_label_as_real))\n",
        "        undummy_df = udummy_german_credit(df)\n",
        "        return_value = (undummy_df, undummy_df.iloc[samples_label_as_real],\n",
        "                        undummy_df.iloc[samples_label_as_fake], generator_output[samples_label_as_real],\n",
        "                        generator_output[samples_label_as_fake])\n",
        "        return return_value\n",
        "    else:\n",
        "        df[['preg', 'plas', 'pres', 'skin', \"insu\", \"mass\", \"pedi\", \"age\"]] = scaler.inverse_transform(df[['preg', 'plas', 'pres', 'skin', \"insu\", \"mass\", \"pedi\", \"age\"]])\n",
        "        samples_label_as_real, samples_label_as_fake = label_samples(generator, discriminator, generator_output)\n",
        "        print(\"number of output the bit the discriminator\")\n",
        "        print(len(samples_label_as_real))\n",
        "        return_value = (df, df.iloc[samples_label_as_real],\n",
        "                        df.iloc[samples_label_as_fake], generator_output[samples_label_as_real],\n",
        "                        generator_output[samples_label_as_fake])\n",
        "        return return_value"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LZsyh60anbUa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 503
        },
        "outputId": "a386b9f8-f341-4ece-e21f-07699722702a"
      },
      "source": [
        "EPOCHS=200\n",
        "history, generator, discriminator,scaler, columes = train_model(\"german_credit\", EPOCHS, 128)\n",
        "results = print_results(history, \"german_credit\", 100, columes, generator, discriminator, 128, scaler)\n",
        "df, samples_label_as_real_norm, samples_label_as_fake_norm, samples_label_as_real, samples_label_as_fake = results\n",
        "#tf.keras.utils.plot_model(generator, show_shapes=True)\n",
        "#tf.keras.utils.plot_model(discriminator, show_shapes=True)\n",
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "reach epoch number 1\n",
            "reach epoch number 2\n",
            "reach epoch number 3\n",
            "reach epoch number 4\n",
            "reach epoch number 5\n",
            "reach epoch number 6\n",
            "reach epoch number 7\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-fd051ee11232>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mEPOCHS\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mhistory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiscriminator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mscaler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"german_credit\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEPOCHS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprint_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"german_credit\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiscriminator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msamples_label_as_real_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msamples_label_as_fake_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msamples_label_as_real\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msamples_label_as_fake\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#tf.keras.utils.plot_model(generator, show_shapes=True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-9-5910f33ba918>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(name, epochs, input_shape)\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0msamples_batch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m             \u001b[0mgen_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdisc_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiscriminator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenerator_optimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiscriminator_optimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"gen\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgen_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-8-6d3a00a3b020>\u001b[0m in \u001b[0;36mtrain_step\u001b[0;34m(samples, generator, discriminator, batch_size, input_shape, generator_optimizer, discriminator_optimizer, bce)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mgrad_of_generator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen_tape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgen_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mgrad_of_discriminator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdisc_tape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdisc_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiscriminator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mgenerator_optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad_of_generator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/backprop.py\u001b[0m in \u001b[0;36mgradient\u001b[0;34m(self, target, sources, output_gradients, unconnected_gradients)\u001b[0m\n\u001b[1;32m   1078\u001b[0m         \u001b[0moutput_gradients\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_gradients\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1079\u001b[0m         \u001b[0msources_raw\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mflat_sources_raw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1080\u001b[0;31m         unconnected_gradients=unconnected_gradients)\n\u001b[0m\u001b[1;32m   1081\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1082\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_persistent\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/imperative_grad.py\u001b[0m in \u001b[0;36mimperative_grad\u001b[0;34m(tape, target, sources, output_gradients, sources_raw, unconnected_gradients)\u001b[0m\n\u001b[1;32m     75\u001b[0m       \u001b[0moutput_gradients\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m       \u001b[0msources_raw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m       compat.as_str(unconnected_gradients.value))\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/backprop.py\u001b[0m in \u001b[0;36m_gradient_function\u001b[0;34m(op_name, attr_tuple, num_inputs, inputs, outputs, out_grads, skip_input_indices, forward_pass_name_scope)\u001b[0m\n\u001b[1;32m    157\u001b[0m       \u001b[0mgradient_name_scope\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mforward_pass_name_scope\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"/\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradient_name_scope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 159\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmock_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mout_grads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    160\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmock_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mout_grads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_grad.py\u001b[0m in \u001b[0;36m_MatMulGrad\u001b[0;34m(op, grad)\u001b[0m\n\u001b[1;32m   1731\u001b[0m   \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1732\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mt_a\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mt_b\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1733\u001b[0;31m     \u001b[0mgrad_a\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmat_mul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtranspose_b\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1734\u001b[0m     \u001b[0mgrad_b\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmat_mul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtranspose_a\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m   \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mt_a\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mt_b\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py\u001b[0m in \u001b[0;36mmat_mul\u001b[0;34m(a, b, transpose_a, transpose_b, name)\u001b[0m\n\u001b[1;32m   5695\u001b[0m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[1;32m   5696\u001b[0m         \u001b[0m_ctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"MatMul\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"transpose_a\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtranspose_a\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"transpose_b\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5697\u001b[0;31m         transpose_b)\n\u001b[0m\u001b[1;32m   5698\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5699\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 182
        },
        "id": "enjOWDtf3U-T",
        "outputId": "1adbfde7-24d9-4578-a72e-4f88896c9611"
      },
      "source": [
        "samples_label_as_real_norm"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-6a478e1cb576>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msamples_label_as_real_norm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'samples_label_as_real_norm' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "lJ8VIBmU8862",
        "outputId": "bb66969f-711e-4ff5-d7f9-b432155e9414"
      },
      "source": [
        "EPOCHS=200\n",
        "history, generator, discriminator,scaler, columes  = train_model(\"diabetes\", EPOCHS, 64)\n",
        "results = print_results(history, \"diabetes\", 100, columes, generator, discriminator, 64, scaler)\n",
        "df, samples_label_as_real_norm, samples_label_as_fake_norm, samples_label_as_real, samples_label_as_fake = results\n",
        "#tf.keras.utils.plot_model(generator, show_shapes=True)\n",
        "#tf.keras.utils.plot_model(discriminator, show_shapes=True)\n",
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "reach epoch number 1\n",
            "reach epoch number 2\n",
            "reach epoch number 3\n",
            "reach epoch number 4\n",
            "reach epoch number 5\n",
            "reach epoch number 6\n",
            "reach epoch number 7\n",
            "reach epoch number 8\n",
            "reach epoch number 9\n",
            "reach epoch number 10\n",
            "reach epoch number 11\n",
            "reach epoch number 12\n",
            "reach epoch number 13\n",
            "reach epoch number 14\n",
            "reach epoch number 15\n",
            "reach epoch number 16\n",
            "reach epoch number 17\n",
            "reach epoch number 18\n",
            "reach epoch number 19\n",
            "reach epoch number 20\n",
            "reach epoch number 21\n",
            "reach epoch number 22\n",
            "reach epoch number 23\n",
            "reach epoch number 24\n",
            "reach epoch number 25\n",
            "reach epoch number 26\n",
            "reach epoch number 27\n",
            "reach epoch number 28\n",
            "reach epoch number 29\n",
            "reach epoch number 30\n",
            "reach epoch number 31\n",
            "reach epoch number 32\n",
            "reach epoch number 33\n",
            "reach epoch number 34\n",
            "reach epoch number 35\n",
            "reach epoch number 36\n",
            "reach epoch number 37\n",
            "reach epoch number 38\n",
            "reach epoch number 39\n",
            "reach epoch number 40\n",
            "reach epoch number 41\n",
            "reach epoch number 42\n",
            "reach epoch number 43\n",
            "reach epoch number 44\n",
            "reach epoch number 45\n",
            "reach epoch number 46\n",
            "reach epoch number 47\n",
            "reach epoch number 48\n",
            "reach epoch number 49\n",
            "reach epoch number 50\n",
            "reach epoch number 51\n",
            "reach epoch number 52\n",
            "reach epoch number 53\n",
            "reach epoch number 54\n",
            "reach epoch number 55\n",
            "reach epoch number 56\n",
            "reach epoch number 57\n",
            "reach epoch number 58\n",
            "reach epoch number 59\n",
            "reach epoch number 60\n",
            "reach epoch number 61\n",
            "reach epoch number 62\n",
            "reach epoch number 63\n",
            "reach epoch number 64\n",
            "reach epoch number 65\n",
            "reach epoch number 66\n",
            "reach epoch number 67\n",
            "reach epoch number 68\n",
            "reach epoch number 69\n",
            "reach epoch number 70\n",
            "reach epoch number 71\n",
            "reach epoch number 72\n",
            "reach epoch number 73\n",
            "reach epoch number 74\n",
            "reach epoch number 75\n",
            "reach epoch number 76\n",
            "reach epoch number 77\n",
            "reach epoch number 78\n",
            "reach epoch number 79\n",
            "reach epoch number 80\n",
            "reach epoch number 81\n",
            "reach epoch number 82\n",
            "reach epoch number 83\n",
            "reach epoch number 84\n",
            "reach epoch number 85\n",
            "reach epoch number 86\n",
            "reach epoch number 87\n",
            "reach epoch number 88\n",
            "reach epoch number 89\n",
            "reach epoch number 90\n",
            "reach epoch number 91\n",
            "reach epoch number 92\n",
            "reach epoch number 93\n",
            "reach epoch number 94\n",
            "reach epoch number 95\n",
            "reach epoch number 96\n",
            "reach epoch number 97\n",
            "reach epoch number 98\n",
            "reach epoch number 99\n",
            "reach epoch number 100\n",
            "reach epoch number 101\n",
            "reach epoch number 102\n",
            "reach epoch number 103\n",
            "reach epoch number 104\n",
            "reach epoch number 105\n",
            "reach epoch number 106\n",
            "reach epoch number 107\n",
            "reach epoch number 108\n",
            "reach epoch number 109\n",
            "reach epoch number 110\n",
            "reach epoch number 111\n",
            "reach epoch number 112\n",
            "reach epoch number 113\n",
            "reach epoch number 114\n",
            "reach epoch number 115\n",
            "reach epoch number 116\n",
            "reach epoch number 117\n",
            "reach epoch number 118\n",
            "reach epoch number 119\n",
            "reach epoch number 120\n",
            "reach epoch number 121\n",
            "reach epoch number 122\n",
            "reach epoch number 123\n",
            "reach epoch number 124\n",
            "reach epoch number 125\n",
            "reach epoch number 126\n",
            "reach epoch number 127\n",
            "reach epoch number 128\n",
            "reach epoch number 129\n",
            "reach epoch number 130\n",
            "reach epoch number 131\n",
            "reach epoch number 132\n",
            "reach epoch number 133\n",
            "reach epoch number 134\n",
            "reach epoch number 135\n",
            "reach epoch number 136\n",
            "reach epoch number 137\n",
            "reach epoch number 138\n",
            "reach epoch number 139\n",
            "reach epoch number 140\n",
            "reach epoch number 141\n",
            "reach epoch number 142\n",
            "reach epoch number 143\n",
            "reach epoch number 144\n",
            "reach epoch number 145\n",
            "reach epoch number 146\n",
            "reach epoch number 147\n",
            "reach epoch number 148\n",
            "reach epoch number 149\n",
            "reach epoch number 150\n",
            "reach epoch number 151\n",
            "reach epoch number 152\n",
            "reach epoch number 153\n",
            "reach epoch number 154\n",
            "reach epoch number 155\n",
            "reach epoch number 156\n",
            "reach epoch number 157\n",
            "reach epoch number 158\n",
            "reach epoch number 159\n",
            "reach epoch number 160\n",
            "reach epoch number 161\n",
            "reach epoch number 162\n",
            "reach epoch number 163\n",
            "reach epoch number 164\n",
            "reach epoch number 165\n",
            "reach epoch number 166\n",
            "reach epoch number 167\n",
            "reach epoch number 168\n",
            "reach epoch number 169\n",
            "reach epoch number 170\n",
            "reach epoch number 171\n",
            "reach epoch number 172\n",
            "reach epoch number 173\n",
            "reach epoch number 174\n",
            "reach epoch number 175\n",
            "reach epoch number 176\n",
            "reach epoch number 177\n",
            "reach epoch number 178\n",
            "reach epoch number 179\n",
            "reach epoch number 180\n",
            "reach epoch number 181\n",
            "reach epoch number 182\n",
            "reach epoch number 183\n",
            "reach epoch number 184\n",
            "reach epoch number 185\n",
            "reach epoch number 186\n",
            "reach epoch number 187\n",
            "reach epoch number 188\n",
            "reach epoch number 189\n",
            "reach epoch number 190\n",
            "reach epoch number 191\n",
            "reach epoch number 192\n",
            "reach epoch number 193\n",
            "reach epoch number 194\n",
            "reach epoch number 195\n",
            "reach epoch number 196\n",
            "reach epoch number 197\n",
            "reach epoch number 198\n",
            "reach epoch number 199\n",
            "reach epoch number 200\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "number of output the bit the discriminator\n",
            "14\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>preg</th>\n",
              "      <th>plas</th>\n",
              "      <th>pres</th>\n",
              "      <th>skin</th>\n",
              "      <th>insu</th>\n",
              "      <th>mass</th>\n",
              "      <th>pedi</th>\n",
              "      <th>age</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.197746</td>\n",
              "      <td>129.500336</td>\n",
              "      <td>70.859642</td>\n",
              "      <td>7.744060</td>\n",
              "      <td>94.191544</td>\n",
              "      <td>25.688812</td>\n",
              "      <td>0.513891</td>\n",
              "      <td>15.733748</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4.603326</td>\n",
              "      <td>101.401154</td>\n",
              "      <td>74.200607</td>\n",
              "      <td>43.654385</td>\n",
              "      <td>211.203506</td>\n",
              "      <td>33.722027</td>\n",
              "      <td>0.178591</td>\n",
              "      <td>27.395844</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2.884568</td>\n",
              "      <td>147.182922</td>\n",
              "      <td>62.930630</td>\n",
              "      <td>2.767864</td>\n",
              "      <td>32.434448</td>\n",
              "      <td>30.658863</td>\n",
              "      <td>0.006352</td>\n",
              "      <td>29.263535</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4.864655</td>\n",
              "      <td>118.750175</td>\n",
              "      <td>74.907166</td>\n",
              "      <td>-5.723094</td>\n",
              "      <td>-4.739881</td>\n",
              "      <td>23.945332</td>\n",
              "      <td>0.202410</td>\n",
              "      <td>27.512581</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.274758</td>\n",
              "      <td>125.328522</td>\n",
              "      <td>63.337803</td>\n",
              "      <td>4.678903</td>\n",
              "      <td>113.453300</td>\n",
              "      <td>20.786207</td>\n",
              "      <td>0.701046</td>\n",
              "      <td>7.099045</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>3.259089</td>\n",
              "      <td>106.374138</td>\n",
              "      <td>64.415222</td>\n",
              "      <td>13.821465</td>\n",
              "      <td>107.025681</td>\n",
              "      <td>21.793312</td>\n",
              "      <td>0.307065</td>\n",
              "      <td>19.401506</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>0.821818</td>\n",
              "      <td>110.056335</td>\n",
              "      <td>57.391197</td>\n",
              "      <td>8.684026</td>\n",
              "      <td>145.519150</td>\n",
              "      <td>20.762579</td>\n",
              "      <td>0.401201</td>\n",
              "      <td>15.455724</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>4.369848</td>\n",
              "      <td>160.753174</td>\n",
              "      <td>80.459763</td>\n",
              "      <td>30.330416</td>\n",
              "      <td>167.491882</td>\n",
              "      <td>40.542435</td>\n",
              "      <td>0.183228</td>\n",
              "      <td>34.074085</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>5.108668</td>\n",
              "      <td>88.636391</td>\n",
              "      <td>67.404945</td>\n",
              "      <td>7.661384</td>\n",
              "      <td>82.761925</td>\n",
              "      <td>24.123569</td>\n",
              "      <td>0.346594</td>\n",
              "      <td>27.550465</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>3.198212</td>\n",
              "      <td>147.805481</td>\n",
              "      <td>73.934616</td>\n",
              "      <td>24.260368</td>\n",
              "      <td>154.119110</td>\n",
              "      <td>28.303041</td>\n",
              "      <td>0.452781</td>\n",
              "      <td>22.719372</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>100 rows × 8 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        preg        plas       pres  ...       mass      pedi        age\n",
              "0   1.197746  129.500336  70.859642  ...  25.688812  0.513891  15.733748\n",
              "1   4.603326  101.401154  74.200607  ...  33.722027  0.178591  27.395844\n",
              "2   2.884568  147.182922  62.930630  ...  30.658863  0.006352  29.263535\n",
              "3   4.864655  118.750175  74.907166  ...  23.945332  0.202410  27.512581\n",
              "4   0.274758  125.328522  63.337803  ...  20.786207  0.701046   7.099045\n",
              "..       ...         ...        ...  ...        ...       ...        ...\n",
              "95  3.259089  106.374138  64.415222  ...  21.793312  0.307065  19.401506\n",
              "96  0.821818  110.056335  57.391197  ...  20.762579  0.401201  15.455724\n",
              "97  4.369848  160.753174  80.459763  ...  40.542435  0.183228  34.074085\n",
              "98  5.108668   88.636391  67.404945  ...  24.123569  0.346594  27.550465\n",
              "99  3.198212  147.805481  73.934616  ...  28.303041  0.452781  22.719372\n",
              "\n",
              "[100 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 174
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WrqlJiHyjVDf"
      },
      "source": [
        "# random forest part"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wlg863rE-_as"
      },
      "source": [
        "# part 2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4exMsgHEAIGs"
      },
      "source": [
        "def train_random_forest(name):\n",
        "    if name == \"diabetes\":\n",
        "        dataset = arff.loadarff('/content/drive/MyDrive/deep4/diabetes.arff')\n",
        "        datasets_df = pd.DataFrame(dataset[0])\n",
        "        dataset_encode_label = datasets_df.copy()\n",
        "        dataset_encode_label[\"class\"].replace({b\"tested_negative\": 0, b\"tested_positive\": 1}, inplace=True)\n",
        "        features_cols = dataset_encode_label.iloc[: , :-1]\n",
        "        label_col = dataset_encode_label.iloc[: , -1]\n",
        "        X_train, X_test, y_train, y_test = train_test_split(features_cols, label_col, test_size=0.3, random_state=42)\n",
        "        scaler = StandardScaler()\n",
        "        X_train = scaler.fit_transform(X_train)\n",
        "        clf = RandomForestClassifier(max_depth=4, random_state=0, n_estimators=500, class_weight={0: 1, 1: 2})\n",
        "        clf.fit(X_train, y_train)\n",
        "        pred = clf.predict(scaler.transform(X_test))\n",
        "        print(accuracy_score(y_test, pred))\n",
        "        return features_cols, scaler, features_cols.columns, clf\n",
        "    else:\n",
        "        dataset = arff.loadarff('/content/drive/MyDrive/deep4/german_credit.arff')\n",
        "        datasets_df = pd.DataFrame(dataset[0])\n",
        "        dataset_encode_label = datasets_df.copy()\n",
        "        dataset_encode_label[\"21\"].replace({b\"1\": 0, b\"2\": 1}, inplace=True)\n",
        "        dataset_encode_label = pd.get_dummies(dataset_encode_label)\n",
        "        label_col = dataset_encode_label[\"21\"]\n",
        "        features_cols = dataset_encode_label.drop([\"21\"], axis=1)\n",
        "        scaler = StandardScaler()\n",
        "        X_train, X_test, y_train, y_test = train_test_split(features_cols, label_col, test_size=0.3, random_state=42)\n",
        "        X_train_scale = X_train.copy()\n",
        "        X_train_scale[[\"2\",\"5\",\"8\",\"11\",\"13\",\"16\",\"18\"]] = scaler.fit_transform(X_train[[\"2\",\"5\",\"8\",\"11\",\"13\",\"16\",\"18\"]])\n",
        "        clf = RandomForestClassifier(max_depth=4, random_state=0, n_estimators=500)\n",
        "        clf.fit(X_train_scale, y_train)\n",
        "        X_test_scale = X_test.copy()\n",
        "        X_test_scale[[\"2\",\"5\",\"8\",\"11\",\"13\",\"16\",\"18\"]] = scaler.transform(X_test[[\"2\",\"5\",\"8\",\"11\",\"13\",\"16\",\"18\"]])\n",
        "        pred = clf.predict(X_test_scale)\n",
        "        print(accuracy_score(y_test, pred))\n",
        "        return features_cols, scaler, features_cols.columns, clf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HmBDcfOoQmA7"
      },
      "source": [
        "def make_generator_model_part2(input_shape, layer_dim, output_dim):\n",
        "    # TODO change\n",
        "    input= tf.keras.layers.Input(shape=input_shape)\n",
        "    input1= tf.keras.layers.Input(shape=(1, ))\n",
        "    embedding = tf.keras.layers.Flatten()(tf.keras.layers.Embedding(2, input_shape[0])(input1))\n",
        "    dense = tf.keras.layers.Dense(embedding.shape[1])(embedding)\n",
        "    layer_output = tf.keras.layers.concatenate([input, dense])\n",
        "    layer_output = tf.keras.layers.Dense(layer_dim, activation=\"relu\")(layer_output)\n",
        "    layer_output = tf.keras.layers.Dense(layer_dim * 3, activation='relu')(layer_output)\n",
        "    layer_output = tf.keras.layers.Dense(layer_dim * 3, activation='relu')(layer_output) # new add\n",
        "    layer_output = tf.keras.layers.Dense(layer_dim * 4, activation='relu')(layer_output)\n",
        "    layer_output = tf.keras.layers.Dense(layer_dim * 4, activation='relu')(layer_output)\n",
        "    layer_output = tf.keras.layers.Dense(output_dim)(layer_output)\n",
        "    return tf.keras.Model(inputs=[input, input1], outputs=layer_output)\n",
        "    \n",
        "\n",
        "def make_generator_model_credit_part2(input_shape, layer_dim, output_dim):\n",
        "    # TODO change\n",
        "    input= tf.keras.layers.Input(shape=input_shape)\n",
        "    input1= tf.keras.layers.Input(shape=(1, ))\n",
        "    embedding = tf.keras.layers.Flatten()(tf.keras.layers.Embedding(2, input_shape[0])(input1))\n",
        "    dense = tf.keras.layers.Dense(embedding.shape[1])(embedding)\n",
        "    layer_output = tf.keras.layers.concatenate([input, dense])\n",
        "    layer_output = tf.keras.layers.Dense(layer_dim, activation=\"relu\")(layer_output)\n",
        "    layer_output = tf.keras.layers.Dense(layer_dim * 2, activation='relu')(layer_output)\n",
        "    layer_output = tf.keras.layers.Dense(layer_dim * 2, activation='relu')(layer_output) # new add\n",
        "    layer_output = tf.keras.layers.Dense(layer_dim * 4, activation='relu')(layer_output)\n",
        "    layer_output = tf.keras.layers.Dense(layer_dim * 4, activation='relu')(layer_output)\n",
        "    layer_output = tf.keras.layers.Dense(output_dim)(layer_output)\n",
        "    return tf.keras.Model(inputs=[input, input1], outputs=layer_output)\n",
        "\n",
        "def make_discriminator_model_part2(input_shape, layer_dim):\n",
        "    input= tf.keras.layers.Input(shape=input_shape)\n",
        "    input1= tf.keras.layers.Input(shape=(1, ))\n",
        "    input2 = tf.keras.layers.Input(shape=(1, ))\n",
        "    \n",
        "    embedding = tf.keras.layers.Embedding(2, input_shape[0])\n",
        "    embedding1 = tf.keras.layers.Flatten()(embedding(input1))\n",
        "    embedding2 = tf.keras.layers.Flatten()(embedding(input2))\n",
        "    z = tf.keras.layers.concatenate([embedding1, embedding2])\n",
        "    dense = tf.keras.layers.Dense(z.shape[1])(z) # TODO think\n",
        "    layer_output = tf.keras.layers.concatenate([input, dense])\n",
        "\n",
        "    layer_output = tf.keras.layers.Dense(layer_dim * 4, activation='relu')(layer_output)\n",
        "    layer_output = tf.keras.layers.Dense(layer_dim * 3, activation='relu')(layer_output)\n",
        "    layer_output = tf.keras.layers.Dense(layer_dim * 3, activation='relu')(layer_output) # remove\n",
        "    layer_output = tf.keras.layers.Dense(layer_dim, activation='relu')(layer_output)\n",
        "    layer_output = tf.keras.layers.Dense(1, activation='sigmoid')(layer_output)\n",
        "    return tf.keras.Model(inputs=[input, input1, input2], outputs=layer_output)\n",
        "\n",
        "def make_discriminator_model_part2_credit(input_shape, layer_dim):\n",
        "    input= tf.keras.layers.Input(shape=input_shape)\n",
        "    input1= tf.keras.layers.Input(shape=(1, ))\n",
        "    input2 = tf.keras.layers.Input(shape=(1, ))\n",
        "    \n",
        "    embedding = tf.keras.layers.Embedding(2, input_shape[0])\n",
        "    embedding1 = tf.keras.layers.Flatten()(embedding(input1))\n",
        "    embedding2 = tf.keras.layers.Flatten()(embedding(input2))\n",
        "    z = tf.keras.layers.concatenate([embedding1, embedding2])\n",
        "    dense = tf.keras.layers.Dense(z.shape[1])(z) # TODO think\n",
        "    layer_output = tf.keras.layers.concatenate([input, dense])\n",
        "\n",
        "    layer_output = tf.keras.layers.Dense(layer_dim * 3, activation='relu')(layer_output)\n",
        "    layer_output = tf.keras.layers.Dense(layer_dim * 2, activation='relu')(layer_output)\n",
        "    layer_output = tf.keras.layers.Dense(layer_dim * 2, activation='relu')(layer_output) # remove\n",
        "    layer_output = tf.keras.layers.Dense(layer_dim, activation='relu')(layer_output)\n",
        "    layer_output = tf.keras.layers.Dense(1, activation='sigmoid')(layer_output)\n",
        "    return tf.keras.Model(inputs=[input, input1, input2], outputs=layer_output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vCiTj-YP7huH"
      },
      "source": [
        "def discriminator_loss_part2(output_disc, real):\n",
        "    return tf.keras.losses.BinaryCrossentropy()(output_disc, real)\n",
        "def generator_loss_part2(output_disc, real):\n",
        "    return tf.keras.losses.BinaryCrossentropy()(output_disc, real)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RVujx56x8EoO"
      },
      "source": [
        "def train_step_part2(counter, generator, discriminator, batch_size, input_shape, generator_optimizer, discriminator_optimizer, clf):\n",
        "    \n",
        "    noise = tf.random.normal([batch_size, input_shape])\n",
        "    #conf = np.random.rand(BATCH_SIZE)\n",
        "    conf = np.ones(batch_size) * np.random.rand(1)\n",
        "    conf_clf = []\n",
        "\n",
        "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
        "      generated_samples = generator([noise, conf], training=True)\n",
        "      \n",
        "      conf_clf = np.array([elem[1] for elem in clf.predict_proba(generated_samples.numpy())])\n",
        "      gen_y = np.zeros(batch_size)\n",
        "      dec_y = np.ones(batch_size)\n",
        "      # TODO check if must\n",
        "      \"\"\"\n",
        "      replace = np.random.randint(2, 4)\n",
        "      for i in range(batch_size):\n",
        "          if i % replace == 0:\n",
        "              temp = conf[i]\n",
        "              conf[i] = conf_clf[i]\n",
        "              conf_clf[i] = temp\n",
        "              dec_y[i] == 0\n",
        "              gen_y[i] == 1\n",
        "      \"\"\"\n",
        "      \n",
        "      if counter %2 ==0:\n",
        "          output = discriminator([generated_samples, conf_clf, conf], training=True)\n",
        "          gen_loss = generator_loss_part2(output, gen_y)\n",
        "          disc_loss = discriminator_loss_part2(output, dec_y)\n",
        "      else:\n",
        "          output = discriminator([generated_samples, conf, conf_clf], training=True)\n",
        "          gen_loss = generator_loss_part2(output, dec_y)\n",
        "          disc_loss = discriminator_loss_part2(output, gen_y)\n",
        "\n",
        "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
        "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
        "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
        "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n",
        "    return gen_loss, disc_loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LSBRAUoPI-ox"
      },
      "source": [
        "def train_model_part2(name, epochs, input_shape):\n",
        "    dataset, scaler, columes, clf = train_random_forest(name)\n",
        "    output_dim = dataset.shape[1]\n",
        "    #buffer_size = 500 TODO check\n",
        "    batch_size = 32\n",
        "\n",
        "    if name == \"german_credit\":\n",
        "        layer_size_gen = 256\n",
        "        layer_size_disc = 128\n",
        "        disc_lr = 1e-4\n",
        "        gen_lr = 1e-4\n",
        "        generator = make_generator_model_part2((input_shape, ), layer_size_gen, output_dim)\n",
        "    else:\n",
        "        layer_size_gen = 256\n",
        "        layer_size_disc = 256\n",
        "        disc_lr = 1e-5\n",
        "        gen_lr = 1e-3\n",
        "        generator = make_generator_model_part2((input_shape, ), layer_size_gen, output_dim)\n",
        "    \n",
        "    \n",
        "    train_dataset = tf.data.Dataset.from_tensor_slices(dataset).batch(batch_size)\n",
        "    \n",
        "    discriminator = make_discriminator_model_part2((output_dim, ), layer_size_disc)\n",
        "    generator_optimizer = tf.keras.optimizers.Adam(gen_lr)\n",
        "    discriminator_optimizer = tf.keras.optimizers.Adam(disc_lr)\n",
        "    history = {}\n",
        "    history[\"gen\"] = []\n",
        "    history[\"disc\"] = []\n",
        "    counter = 0 \n",
        "    for epoch in range(epochs):\n",
        "        for _ in train_dataset:\n",
        "            gen_loss, disc_loss = train_step_part2(counter, generator, discriminator, batch_size, input_shape, generator_optimizer, discriminator_optimizer, clf)\n",
        "            counter += 1\n",
        "      \n",
        "        history[\"gen\"].append(gen_loss.numpy())\n",
        "        history[\"disc\"].append(disc_loss.numpy())\n",
        "        print(f\"reach epoch number {epoch + 1}\")\n",
        "    return history, generator, discriminator, scaler, columes, clf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sQNTLdNzT_IK"
      },
      "source": [
        "def print_results_part2(history, name, num_examples_to_generate, dataset_columns, generator, discriminator, input_shape, scaler):\n",
        "    plot(history)\n",
        "    if name == \"german_credit\":\n",
        "        seed = tf.random.normal([num_examples_to_generate, input_shape])\n",
        "        conf = np.random.rand(num_examples_to_generate , 1)\n",
        "        generator_output = generator([seed, conf]).numpy()\n",
        "        df = pd.DataFrame(data= generator_output.copy(), columns=dataset_columns)\n",
        "        df[[\"2\",\"5\",\"8\",\"11\",\"13\",\"16\",\"18\"]] = scaler.inverse_transform(df[[\"2\",\"5\",\"8\",\"11\",\"13\",\"16\",\"18\"]])\n",
        "        #print(\"number of output the bit the discriminator\")\n",
        "        #print((discriminator(generator_output)>0.5).numpy().sum())\n",
        "        return udummy_german_credit(df), generator_output, conf\n",
        "    else:\n",
        "        seed = tf.random.normal([num_examples_to_generate, input_shape])\n",
        "        conf = np.random.rand(num_examples_to_generate , 1)\n",
        "        generator_output = generator([seed, conf]).numpy()\n",
        "        df = pd.DataFrame(data= generator_output.copy(), columns=dataset_columns)\n",
        "        df[['preg', 'plas', 'pres', 'skin', \"insu\", \"mass\", \"pedi\", \"age\"]] = scaler.inverse_transform(df[['preg', 'plas', 'pres', 'skin', \"insu\", \"mass\", \"pedi\", \"age\"]])\n",
        "        #print(\"number of output the bit the discriminator\")\n",
        "        #print((discriminator(generator_output)>0.5).numpy().sum())\n",
        "        return df, generator_output, conf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 536
        },
        "id": "jKVTdAokAr5b",
        "outputId": "50fd3950-d25d-44dc-90a6-b71ad641ead0"
      },
      "source": [
        "EPOCHS=100\n",
        "history, generator, discriminator, scaler, columes, clf = train_model_part2(\"german_credit\", EPOCHS, 256)\n",
        "df, samples, conf = print_results_part2(history, \"german_credit\", 32, columes, generator, discriminator, 256, scaler) \n",
        "#tf.keras.utils.plot_model(generator, show_shapes=True)\n",
        "#tf.keras.utils.plot_model(discriminator, show_shapes=True)\n",
        "#clf.predict_proba(samples[0:30])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.7133333333333334\n",
            "reach epoch number 1\n",
            "reach epoch number 2\n",
            "reach epoch number 3\n",
            "reach epoch number 4\n",
            "reach epoch number 5\n",
            "reach epoch number 6\n",
            "reach epoch number 7\n",
            "reach epoch number 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-f5122b4087a6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mEPOCHS\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mhistory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiscriminator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model_part2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"german_credit\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEPOCHS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m256\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msamples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprint_results_part2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"german_credit\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiscriminator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#tf.keras.utils.plot_model(generator, show_shapes=True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#tf.keras.utils.plot_model(discriminator, show_shapes=True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-26-d764c9f4cfe8>\u001b[0m in \u001b[0;36mtrain_model_part2\u001b[0;34m(name, epochs, input_shape)\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m             \u001b[0mgen_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdisc_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_step_part2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcounter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiscriminator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenerator_optimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiscriminator_optimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m             \u001b[0mcounter\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-25-d065c47dac0f>\u001b[0m in \u001b[0;36mtrain_step_part2\u001b[0;34m(counter, generator, discriminator, batch_size, input_shape, generator_optimizer, discriminator_optimizer, clf)\u001b[0m\n\u001b[1;32m     33\u001b[0m           \u001b[0mdisc_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdiscriminator_loss_part2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgen_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m     \u001b[0mgradients_of_generator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen_tape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgen_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m     \u001b[0mgradients_of_discriminator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdisc_tape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdisc_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiscriminator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0mgenerator_optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradients_of_generator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/backprop.py\u001b[0m in \u001b[0;36mgradient\u001b[0;34m(self, target, sources, output_gradients, unconnected_gradients)\u001b[0m\n\u001b[1;32m   1078\u001b[0m         \u001b[0moutput_gradients\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_gradients\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1079\u001b[0m         \u001b[0msources_raw\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mflat_sources_raw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1080\u001b[0;31m         unconnected_gradients=unconnected_gradients)\n\u001b[0m\u001b[1;32m   1081\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1082\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_persistent\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/imperative_grad.py\u001b[0m in \u001b[0;36mimperative_grad\u001b[0;34m(tape, target, sources, output_gradients, sources_raw, unconnected_gradients)\u001b[0m\n\u001b[1;32m     75\u001b[0m       \u001b[0moutput_gradients\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m       \u001b[0msources_raw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m       compat.as_str(unconnected_gradients.value))\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/backprop.py\u001b[0m in \u001b[0;36m_gradient_function\u001b[0;34m(op_name, attr_tuple, num_inputs, inputs, outputs, out_grads, skip_input_indices, forward_pass_name_scope)\u001b[0m\n\u001b[1;32m    157\u001b[0m       \u001b[0mgradient_name_scope\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mforward_pass_name_scope\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"/\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradient_name_scope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 159\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmock_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mout_grads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    160\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmock_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mout_grads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_grad.py\u001b[0m in \u001b[0;36m_MatMulGrad\u001b[0;34m(op, grad)\u001b[0m\n\u001b[1;32m   1731\u001b[0m   \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1732\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mt_a\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mt_b\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1733\u001b[0;31m     \u001b[0mgrad_a\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmat_mul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtranspose_b\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1734\u001b[0m     \u001b[0mgrad_b\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmat_mul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtranspose_a\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m   \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mt_a\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mt_b\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py\u001b[0m in \u001b[0;36mmat_mul\u001b[0;34m(a, b, transpose_a, transpose_b, name)\u001b[0m\n\u001b[1;32m   5695\u001b[0m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[1;32m   5696\u001b[0m         \u001b[0m_ctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"MatMul\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"transpose_a\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtranspose_a\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"transpose_b\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5697\u001b[0;31m         transpose_b)\n\u001b[0m\u001b[1;32m   5698\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5699\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SoQh3Y_0e1E2"
      },
      "source": [
        "EPOCHS=120\n",
        "history, generator, discriminator, scaler, columes, clf = train_model_part2(\"diabetes\", EPOCHS, 128)\n",
        "df, samples, conf = print_results_part2(history, \"diabetes\", 32, columes, generator, discriminator, 128, scaler)\n",
        "clf.predict_proba(samples[0:30])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Mw5U_q_TYZ0"
      },
      "source": [
        "while True:\n",
        "    pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NYWjd4X0JDvC"
      },
      "source": [
        "print(\"seed\")\n",
        "#seed = tf.random.normal([1, INPUT_SHAPE])\n",
        "noise = tf.random.normal([32, 128])\n",
        "#print(noise)\n",
        "conf = np.random.rand(32 , 1)\n",
        "#print(conf)\n",
        "#s = generator1([noise, np.array([0.3])])\n",
        "s = generator([noise, conf])\n",
        "#print(s)\n",
        "\n",
        "#print(clf.predict_proba(s.numpy()))\n",
        "print(clf.predict_proba(s.numpy()))\n",
        "#print(scaler.inverse_transform(s.numpy()).round(3))\n",
        "#(discriminator(generator(seed))>0.5).numpy().sum()\n",
        "#print(discriminator1([s, np.array([0.1]), np.array([0.2])]))\n",
        "\n",
        "#scaler.inverse_transform(diabetes_df_new_new)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}